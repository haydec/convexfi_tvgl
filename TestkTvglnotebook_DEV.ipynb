{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from ktvgl_functions import init_parameters, fit_multivariate_t, L_update, w_update,  u_update, a_update, V_update, dual_update, residual_Update, update_parameters, updateADMMpenalties, L_star,L_from_w,D_star,D_from_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 4.539992976248485e-07\n"
     ]
    }
   ],
   "source": [
    "log_rw_returns = pd.read_csv(\"log_rw_returns.csv\")\n",
    "winLen = 200\n",
    "Xraw = log_rw_returns[0:winLen]\n",
    "\n",
    "maxIter = 200\n",
    "update_rho = True\n",
    "update_eta = True\n",
    "early_stopping = False\n",
    "\n",
    "\n",
    "X = scale(Xraw.to_numpy())\n",
    "\n",
    "# number of nodes\n",
    "p = X.shape[1] # n_features\n",
    "k = 1 # n_clusters\n",
    "\n",
    "# number of observations\n",
    "T_n = X.shape[0]      # n_observations in Frame\n",
    "sigma_e = np.exp(10) # Student T Distribution Standard Dev. \n",
    "alpha = 2/(T_n*sigma_e)\n",
    "beta = 2*np.log(sigma_e)/T_n\n",
    "\n",
    "print(\"alpha\",alpha)\n",
    "rho = 2    # ADMM hyperparameter. \n",
    "gamma = 10 # hyperparameter that controls the sparsity of VAR coefficients\n",
    "eta = 1e-8 # hyperparameter that controls the regularization to obtain a k-component graph\n",
    "#tau = 2 # Not used\n",
    "#mu = 2 # Not used\n",
    "\n",
    "\n",
    "# BOOK KEEPING\n",
    "# residual vectors\n",
    "primal_lap_residual = np.array([], dtype=float)\n",
    "primal_deg_residual = np.array([], dtype=float)\n",
    "dual_residual       = np.array([], dtype=float)\n",
    "\n",
    "lagrangian = np.array([], dtype=float)\n",
    "rho_seq = np.array([], dtype=float)\n",
    "eta_seq = np.array([], dtype=float)\n",
    "\n",
    "elapsed_time = np.array([], dtype=float)\n",
    "\n",
    "\n",
    "mu, Sigma, nu, history = fit_multivariate_t( X, nu_init=30.0, max_iter=200, tol=1e-6, fix_nu=None, jitter=1e-6, verbose=False)\n",
    "w, Aw, a, w_lagged, L_n, Phi_n, u_n, mu_vec, d, z_n, V = init_parameters(X,k)\n",
    "nu = 10.02571\n",
    "#print(\"w\",w)\n",
    "#print(\"Aw\",Aw)\n",
    "#print(\"a\",a)\n",
    "#print(\"w_lagged\",w_lagged)\n",
    "#print(\"L_n\",L_n)\n",
    "#print(\"Phi_n\",Phi_n)\n",
    "#print(\"u_n\",u_n)\n",
    "#print(\"mu_vec\",mu_vec)\n",
    "#print(\"d\",d)\n",
    "#print(\"z_n\",z_n)\n",
    "#print(\"V\",V)\n",
    "\n",
    "#print(\"nu\",nu)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iter in range(0,maxIter):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #wUpdate = w_update(X, w, w_lagged,a,  nu, L_n, L_nUpdate,  u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta)\n",
    "    wUpdate = w_update(X, w, w_lagged, a, nu, L_n, u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta)            \n",
    "    #print(\"wUpdate\",wUpdate)\n",
    "    u_nUpdate = u_update(wUpdate,a,w_lagged,mu_vec,rho,alpha)\n",
    "    #print(\"u_nUpdate\",u_nUpdate)\n",
    "    # x_update()\n",
    "    aUpdate =a_update( w_lagged, wUpdate, u_nUpdate, mu_vec, gamma, rho)\n",
    "    #print(\"aUpdate\",aUpdate)\n",
    "    vUpdate = V_update(wUpdate,k)\n",
    "    #print(\"vUpdate\",vUpdate)\n",
    "\n",
    "    L_nUpdate = L_update(wUpdate, Phi_n, rho, k)\n",
    "    #print(\"L_nUpdate\")\n",
    "    #print(L_nUpdate)\n",
    "\n",
    "    Phi_nUpdate, mu_vecUpdate, z_nUpdate, Phi_n_res, u_n_res, z_n_res = dual_update(rho, wUpdate, L_nUpdate, Phi_n, aUpdate, w_lagged, mu_vec, u_nUpdate, d, z_n)\n",
    "    #print(\"Phi_nUpdate\")\n",
    "    #print(Phi_nUpdate)\n",
    "    #print(\"mu_vecUpdate\",mu_vecUpdate)\n",
    "    #print(\"z_nUpdate\",z_nUpdate)\n",
    "    primal_lap_residual, primal_deg_residual, dual_residual = residual_Update(rho, L_n, L_nUpdate, Phi_n_res, z_n_res, primal_lap_residual, primal_deg_residual, dual_residual)\n",
    "    #print(\"primal_lap_residual\",primal_lap_residual) \n",
    "    #print(\"primal_deg_residual\",primal_deg_residual) \n",
    "    #print(\"dual_residual\",dual_residual)\n",
    "    \n",
    "    rho, eta, rho_seq, eta_seq, has_converged = updateADMMpenalties( update_rho, rho, rho_seq,L_n, k, wUpdate, update_eta, eta, eta_seq, early_stopping)\n",
    "    #print(\"rho\",rho) \n",
    "    #print(\"eta\",eta) \n",
    "    #print(\"rho_seq\",rho_seq)\n",
    "    #print(\"eta_seq\",eta_seq)\n",
    "    #print(\"has_converged\",has_converged)\n",
    "\n",
    "    \n",
    "    L_n, w, u_n, a, V, Phi_n, mu_vec, z_n = update_parameters( L_nUpdate, wUpdate, u_nUpdate, aUpdate, vUpdate, Phi_nUpdate, mu_vecUpdate, z_nUpdate)\n",
    "\n",
    "    if has_converged:\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78afc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000001 , -0.2122269 , -0.29774266, -0.20305625, -0.2869743 ],\n",
       "       [-0.2122269 ,  1.00000047, -0.23225074, -0.30945238, -0.24607046],\n",
       "       [-0.29774266, -0.23225074,  0.99999993, -0.24527122, -0.22473532],\n",
       "       [-0.20305625, -0.30945238, -0.24527122,  0.9999998 , -0.24221995],\n",
       "       [-0.2869743 , -0.24607046, -0.22473532, -0.24221995,  1.00000002]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dual_update( rho, wUpdate, L_nUpdate, Phi_n, aUpdate, w_lagged, mu_vec, u_nUpdate, d, z_n):\n",
    "\n",
    "    '''\n",
    "    rho:      (1)                              ADMM Hyperparameter  \n",
    "\n",
    "    wUpdate:   ( n_features*(n_features-1)/2 )  Updated Graph Weights for current Frame\n",
    "    L_nUpdate: ( n_features, n_features )       Updated Laplacian Constrained Graph Matrix\n",
    "    Phi_n:     ( n_features, n_features )       Laplacian Constrained Graph Matrix Dual\n",
    "\n",
    "    aUpdate:   ( n_features*(n_features-1)/2 )  Updated VAR Weights for Previous Frame\n",
    "    w_lagged:  ( n_features*(n_features-1)/2 )  Graph Weights for previous Frame  \n",
    "    u_nUpdate: ( n_features*(n_features-1)/2 )  Updated Temporal Consistency Parameter\n",
    "    mu_vec:    ( n_features*(n_features-1)/2 )  Temporal Consistency Parameter Dual \n",
    "\n",
    "    z_n:         (n_features)                   Degree Dual \n",
    "    d:           (1)                            Degree Constraint\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # update Phi\n",
    "    Phi_n_res =  L_from_w(wUpdate) - L_nUpdate\n",
    "    Phi_nUpdate = Phi_n + rho * Phi_n_res\n",
    "\n",
    "    # update mu\n",
    "    u_n_res = u_nUpdate - wUpdate + np.multiply(aUpdate,w_lagged) \n",
    "    mu_vecUpdate = mu_vec + rho * u_n_res\n",
    "\n",
    "    # update z\n",
    "    z_n_res = D_from_w(wUpdate) - d\n",
    "    z_nUpdate = z_n + rho * z_n_res\n",
    "\n",
    "    return Phi_nUpdate, mu_vecUpdate, z_nUpdate, Phi_n_res, u_n_res, z_n_res\n",
    "\n",
    "Phi_nUpdate, mu_vecUpdate, z_nUpdate, Phi_n_res, u_n_res, z_n_res = dual_update(rho, wUpdate, L_nUpdate, Phi_n, aUpdate, w_lagged, mu_vec, u_nUpdate, d, z_n)\n",
    "print(\"Phi_nUpdate\")\n",
    "print(Phi_nUpdate)\n",
    "print(\"mu_vecUpdate\",mu_vecUpdate)\n",
    "print(\"z_nUpdate\",z_nUpdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4711c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0816fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softThresh(v,thr):\n",
    "\n",
    "    '''\n",
    "    v:   ( )  Value(s) to be Threshed  \n",
    "    thr: (1) Threshold Value\n",
    "    '''\n",
    "\n",
    "    temp = np.abs(v) - thr\n",
    "    temp = temp*(temp>0)\n",
    "    return(np.sign(v)*temp)\n",
    "\n",
    "\n",
    "def u_update(wUpdate,a,w_lagged,mu_vec,rho,alpha):\n",
    "\n",
    "    '''\n",
    "    wUpdate:  ( n_features*(n_features-1)/2 )  Updated Graph Weights for current Frame\n",
    "    a:        ( n_features*(n_features-1)/2 )  VAR Weights for Previous Frame\n",
    "    w_lagged: ( n_features*(n_features-1)/2 )  Graph Weights for previous Frame\n",
    "\n",
    "    mu_vec:   ( n_features*(n_features-1)/2 )  Temporal Consistency Parameter Dual\n",
    "    alpha:    (1)                              Temporal Weight Sparsity Hyperparameter\n",
    "    rho:      (1)                              ADMM Hyperparameter\n",
    "    '''\n",
    "\n",
    "    # Update u\n",
    "    u_nTemp  = wUpdate - a*w_lagged - mu_vec/rho\n",
    "    print(\"u_nTemp\", u_nTemp)\n",
    "    thr = alpha/(rho)\n",
    "    print(\"thr\", thr)\n",
    "    u_nUpdate = softThresh(u_nTemp, thr)\n",
    "    return u_nUpdate\n",
    "\n",
    "print(\"wUpdate\",wUpdate)\n",
    "u_nUpdate = u_update(wUpdate,a,w_lagged,mu_vec,rho,alpha)\n",
    "print(\"u_nUpdate\",u_nUpdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softThresh(v,thr):\n",
    "\n",
    "    '''\n",
    "    v:   ( )  Value(s) to be Threshed  \n",
    "    thr: (1) Threshold Value\n",
    "    '''\n",
    "\n",
    "    temp = abs(v) - thr\n",
    "    temp = temp*(temp>0)\n",
    "    return(np.sign(v)*temp)\n",
    "\n",
    "def a_update2( w_lagged, wUpdate, u_nUpdate, mu_vec, gamma, rho):\n",
    "    '''\n",
    "    wUpdate:  ( n_features*(n_features-1)/2 )  Updated Graph Weights for current Frame\n",
    "    u_nUpdate:( n_features*(n_features-1)/2 )  Updated Temporal Consistency Parameter\n",
    "    mu_vec:   ( n_features*(n_features-1)/2 )  Temporal Consistency Parameter Dual \n",
    "    gamma:    (1)                              Hyperparameter that controls the sparsity of VAR coefficients\n",
    "    rho:      (1)                              ADMM Hyperparameter    \n",
    "    '''\n",
    "    \n",
    "    aUpdate = np.zeros_like(w_lagged) # ( n_features*(n_features-1)/2 )  Updated VAR Weights for current Frame\n",
    "    \n",
    "    f_temp = wUpdate - u_nUpdate - mu_vec/rho\n",
    "    f_temp[f_temp<0] = 0\n",
    "    idx = w_lagged > 0\n",
    "    thr = gamma/(rho* w_lagged[idx]**2)\n",
    "    aUpdate[idx] = softThresh(f_temp[idx]/w_lagged[idx], thr)\n",
    "    aUpdate [~idx] = 0\n",
    "    return aUpdate\n",
    "\n",
    "aUpdate = a_update2( w_lagged, wUpdate, u_nUpdate, mu_vec, gamma, rho)\n",
    "\n",
    "aUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bcd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_update2(X, w, w_lagged, a, nu, L_n, u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta):\n",
    "    \"\"\"\n",
    "    NumPy translation of the R weight update (student-t case), matching the paper's Eq. (20)–(21).\n",
    "\n",
    "    Shapes:\n",
    "      X: (T_n, p)\n",
    "      w, w_lagged, a, u_n, mu_vec: (m,) with m = p*(p-1)//2\n",
    "      L_n, L_nUpdate, Phi_n: (p, p)\n",
    "      z_n: (p,)\n",
    "      V: (p, k)\n",
    "      d, nu, rho, eta, beta: scalars (or d can be length-p)\n",
    "\n",
    "    Requires user-provided operators:\n",
    "      L_star: (p,p) -> (m,)\n",
    "      D_star: (p,)  -> (m,)\n",
    "      D_from_w: (m,) -> (p,)\n",
    "    \"\"\"\n",
    "\n",
    "    T_n, p = X.shape\n",
    "    m = w.shape[0]\n",
    "\n",
    "    Lw = L_from_w(w)\n",
    "    LstarLw = L_star(Lw)\n",
    "    DstarDw = D_star(np.diag(Lw))\n",
    "\n",
    "    LstarSq = [None] * T_n\n",
    "    for t in range(T_n):\n",
    "        x = X[t, :]\n",
    "        LstarSq[t] = L_star(np.outer(x, x))  # L_star: (p,p) -> (m,)\n",
    "    #print(\"LstarSq\",LstarSq)\n",
    "\n",
    "    \n",
    "    LstarSweighted = np.repeat(0, .5*p*(p-1))\n",
    "    S_tilde = np.repeat(0, .5*p*(p-1))\n",
    "    #print(\"Init LstarSweighted\",LstarSweighted)\n",
    "    for t in range(T_n):\n",
    "        #LstarSweighted = LstarSweighted + LstarSq[t] * (p + nu) / (float(np.dot(w, LstarSq[t])) + nu )\n",
    "        x = X[t, :]\n",
    "        #LstarSweighted = LstarSweighted + L_star(np.outer(x, x)) * ( (p + nu) / ( L_star(x.T * Lw * x)  + nu ) )\n",
    "        S_tilde = S_tilde + L_star(np.outer(x, x)) * ( (p + nu) / ( L_star(x.T * Lw * x)  + nu ) )\n",
    "\n",
    "    #print(\"LstarSweighted/T_n\",S_tilde/T_n)\n",
    "\n",
    "    #a_w = LstarSweighted/T_n + L_star(eta * (V @ V.T) + Phi_n - rho * (L_n)) + rho*LstarLw\n",
    "    a_w = S_tilde/T_n + L_star(eta * (V @ V.T) + Phi_n + rho * (Lw -L_n))\n",
    "    #print(\"a_w\",a_w)\n",
    "\n",
    "\n",
    "    d_vec = np.full(p, d, dtype=float) if np.ndim(d) == 0 else d\n",
    "    b_w = -mu_vec - rho * (u_n + a * w_lagged) + D_star(z_n - rho * (d_vec - D_from_w(w)))\n",
    "    #print(\"b_w\",b_w)\n",
    "\n",
    "    grad = a_w + b_w\n",
    "    #print(\"aw + bw\", grad)\n",
    "\n",
    "    ratio = 1 / (rho*(4*p-1))\n",
    "    w_new = (1-rho*ratio)*w - ratio *  grad\n",
    "\n",
    "    thr = np.sqrt( 2*beta *ratio )\n",
    "    w_new[w_new< thr] = 0\n",
    "\n",
    "    return w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wUpdate  = w_update2(X, w, w_lagged, a, nu, L_n, L_nUpdate, u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta)\n",
    "wUpdate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lw = L_from_w(w)\n",
    "x = X[1, :]\n",
    "x.T * Lw * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_update3(X, w, w_lagged, a, nu, L_n, u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta):\n",
    "    '''\n",
    "    X:           (n_samples, n_features)        Data Array For Window (Frame) Length\n",
    "\n",
    "    w:           (n_features*(n_features-1)/2)  Graph Weights for current Frame\n",
    "    w_lagged:    (n_features*(n_features-1)/2)  Graph Weights for previous Frame\n",
    "    a            (n_features*(n_features-1)/2)  VAR Weights for Previous Frame\n",
    "    u_n:         (n_features*(n_features-1)/2)  Temporal Consistency Parameter\n",
    "    mu_vec:      (n_features*(n_features-1)/2)  Temporal Consistency Parameter Dual\n",
    "\n",
    "    L_n:         (n_features, n_features)       Updated Laplacian Constrained Graph Matrix\n",
    "    Phi_n:       (n_features, n_features)       Laplacian Constrained Graph Matrix Dual\n",
    "    \n",
    "    \n",
    "    z_n:         (n_features)                   Degree Dual \n",
    "    d:           (1)                            Degree Constraint\n",
    "    \n",
    "\n",
    "    V:           (n_features, n_clusters)       Penalty to control rank of Ln\n",
    "\n",
    "    nu           (1)                            Student T Degrees Of Freedom Parameter\n",
    "    rho:         (1)                            ADMM Hyperparameter    \n",
    "    eta          (1)                            Hyperparameter that controls the regularization to obtain a k-component graph\n",
    "    beta         (1)                            Weight Sparsity Hyperparameter\n",
    "    '''\n",
    "\n",
    "    T_n = X.shape[0] # Window (Frame) Length\n",
    "    p = X.shape[1]   # Number Of Features\n",
    "\n",
    "    Lw = L_from_w(w) # (n_features, n_features) Laplacian with current weights\n",
    "\n",
    "    S_tilde = np.repeat(0, .5*p*(p-1))\n",
    "\n",
    "    for t in range(T_n):\n",
    "        x = X[t, :]\n",
    "        S_tilde = S_tilde + L_star(np.outer(x, x)) * ( (p + nu) / ( L_star(x.T * Lw * x)  + nu ) )\n",
    "\n",
    "\n",
    "    a_w = S_tilde/T_n + L_star(eta * (V @ V.T) + Phi_n + rho * (Lw -L_n))\n",
    "\n",
    "    d_vec = np.full(p, d, dtype=float) if np.ndim(d) == 0 else d\n",
    "    b_w = -mu_vec - rho * (u_n + a * w_lagged) + D_star(z_n - rho * (d_vec - D_from_w(w)))\n",
    " \n",
    "\n",
    "    ratio = 1 / (rho*(4*p-1))\n",
    "    c_w = (1-rho*ratio)*w - ratio *  (a_w + b_w)\n",
    "\n",
    "    thr = np.sqrt( 2*beta *ratio )\n",
    "    w_new = np.multiply(c_w > thr, c_w)\n",
    "\n",
    "    return w_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "wUpdate  = w_update3(X, w, w_lagged, a, nu, L_n, u_n, mu_vec, z_n, Phi_n, V, rho, d, eta, beta)\n",
    "wUpdate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
