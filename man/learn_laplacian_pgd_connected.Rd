% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparse-graph.R
\name{learn_laplacian_pgd_connected}
\alias{learn_laplacian_pgd_connected}
\title{Learns sparse Laplacian matrix of a connected graph

Learns a connected graph via non-convex, sparse promoting regularization
functions such as MCP, SCAD, and re-weighted l1-norm.}
\usage{
learn_laplacian_pgd_connected(
  X,
  w0 = NULL,
  alpha = 0,
  nu = 2,
  heavy_type = "student",
  sparsity_type = "none",
  eps = 1e-04,
  gamma = 2.001,
  q = 1,
  backtrack = TRUE,
  maxiter = 10000,
  reltol = 1e-05,
  verbose = TRUE
)
}
\arguments{
\item{w0}{initial estimate for the weight vector the graph.}

\item{alpha}{hyperparameter to control the level of sparsiness of the
estimated graph}

\item{sparsity_type}{type of non-convex sparsity regularization. Available
methods are: "mcp", "scad", "re-l1", and "none"}

\item{eps}{hyperparameter for the re-weighted l1-norm}

\item{backtrack}{whether to update the learning rate using backtrack line
search}

\item{maxiter}{maximum number of iterations}

\item{reltol}{relative tolerance on the Frobenius norm of the estimated
Laplacian matrix as a stopping criteria}

\item{verbose}{whether or not to show a progress bar displaying the
iterations}

\item{S}{a pxp sample covariance/correlation matrix, where p is the number
of nodes of the graph}

\item{eta}{learning rate}
}
\value{
A list containing possibly the following elements:
\item{\code{laplacian}}{the estimated Laplacian Matrix}
\item{\code{adjacency}}{the estimated Adjacency Matrix}
\item{\code{maxiter}}{number of iterations taken to converge}
\item{\code{convergence}}{boolean flag to indicate whether or not the optimization converged}
\item{\code{elapsed_time}}{elapsed time recorded at every iteration}
}
\description{
Learns sparse Laplacian matrix of a connected graph

Learns a connected graph via non-convex, sparse promoting regularization
functions such as MCP, SCAD, and re-weighted l1-norm.
}
\author{
Ze Vinicius, Jiaxi Ying, and Daniel Palomar
}
