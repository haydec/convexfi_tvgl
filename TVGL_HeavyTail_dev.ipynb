{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ef89497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63709b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_price = pd.read_csv(\"rw_price.csv\")\n",
    "rw_returns = pd.read_csv(\"rw_returns.csv\")\n",
    "log_rw_returns = pd.read_csv(\"log_rw_returns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ade654f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.34982739, 0.32699292, 0.27549521, 0.34886486],\n",
       "       [0.34982739, 1.        , 0.37785361, 0.33174046, 0.32484628],\n",
       "       [0.32699292, 0.37785361, 1.        , 0.33200448, 0.34886946],\n",
       "       [0.27549521, 0.33174046, 0.33200448, 1.        , 0.32947489],\n",
       "       [0.34886486, 0.32484628, 0.34886946, 0.32947489, 1.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winLen = 200\n",
    "Nday = len(log_rw_returns)\n",
    "print(Nday)\n",
    "\n",
    "S_cov = np.corrcoef(scale(log_rw_returns).T)\n",
    "S_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612a128",
   "metadata": {},
   "source": [
    "### Checking Graph operators from \n",
    "A Unified Framework for Structured Graph Learning via Spectral Constraints\n",
    "\n",
    "https://jmlr.org/papers/volume21/19-276/19-276.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c1d452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_from_L(M: np.ndarray) -> np.ndarray:\n",
    "    M = np.asarray(M)\n",
    "    if M.ndim != 2 or M.shape[0] != M.shape[1]:\n",
    "        raise ValueError(\"M must be a square matrix\")\n",
    "\n",
    "    n = M.shape[0]\n",
    "    w = np.empty(n * (n - 1) // 2, dtype=M.dtype)\n",
    "    k = 0\n",
    "    for i in range(n - 1):            # i = 0 .. n-2\n",
    "        for j in range(i + 1, n):     # j = i+1 .. n-1 (strict upper)\n",
    "            w[k] = -M[i, j]\n",
    "            k += 1\n",
    "    return w\n",
    "\n",
    "def L_from_w(w: np.ndarray) -> np.ndarray:\n",
    "    w = np.asarray(w).ravel()\n",
    "    k = w.size\n",
    "    n = int((1 + np.sqrt(1 + 8 * k)) / 2)\n",
    "    if n * (n - 1) // 2 != k:\n",
    "        raise ValueError(\"Invalid length of w: must be n(n-1)/2 for some integer n.\")\n",
    "\n",
    "    Lw = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    # Fill the strict upper triangle row by row, backwards like in C++\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        j = n - i - 1\n",
    "        # Equivalent of Eigen: Lw.row(i).tail(j) = -w.head(k).tail(j)\n",
    "        Lw[i, -j:] = -w[:k][-j:]\n",
    "        k -= j\n",
    "\n",
    "    # Make symmetric: copy upper triangle into lower\n",
    "    Lw = Lw + Lw.T\n",
    "\n",
    "    # Adjust diagonal: subtract column sums\n",
    "    colsum = Lw.sum(axis=0)\n",
    "    np.fill_diagonal(Lw, Lw.diagonal() - colsum)\n",
    "\n",
    "    return Lw\n",
    "\n",
    "def W_init(M):\n",
    "    W0 = w_from_L(M)\n",
    "    W0[W0 < 0] = 0\n",
    "    return W0\n",
    "\n",
    "def L_star(Y):\n",
    "\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    if Y.ndim != 2 or Y.shape[0] != Y.shape[1]:\n",
    "        raise ValueError(\"Y must be a square matrix.\")\n",
    "    p = Y.shape[0]\n",
    "    Lstar = np.zeros(int(p*(p-1)/2))\n",
    "\n",
    "    for i in range(1,p+1):\n",
    "\n",
    "        for j in range(1,p+1):\n",
    "           \n",
    "            if (i > j):\n",
    "                k = int( (i - j) + ((j - 1)/2)*(2*p - j) ) \n",
    "                Lstar[k-1] = Y[i-1,i-1] - Y[i-1, j-1] - Y[ j-1, i-1] + Y[ j-1, j-1]\n",
    "\n",
    "\n",
    "    return Lstar\n",
    "\n",
    "def A_from_w(w):\n",
    "\n",
    "    w = np.asarray(w, dtype=float).ravel()\n",
    "    k = w.size\n",
    "\n",
    "    # Infer n from k = n*(n-1)/2\n",
    "    n_float = (1 + np.sqrt(1 + 8*k)) / 2\n",
    "    n = int(n_float)\n",
    "    if n*(n-1)//2 != k:\n",
    "        raise ValueError(f\"len(w)={k} is not a triangular number; expected k=n*(n-1)/2.\")\n",
    "\n",
    "    A = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    # Indices of strict upper triangle in row-major order\n",
    "    iu = np.triu_indices(n, k=1)\n",
    "    A[iu] = w            # fill upper triangle\n",
    "    A[(iu[1], iu[0])] = w  # mirror to lower triangle\n",
    "    return A\n",
    "\n",
    "def w_from_A(M):\n",
    "    \n",
    "    N = M.shape[1]\n",
    "    k = N * (N - 1) // 2\n",
    "    w = np.zeros(k)\n",
    "    l = 0\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        for j in range(i + 1, N):\n",
    "            w[l] = M[i, j]\n",
    "            l += 1\n",
    "    return w\n",
    "\n",
    "\n",
    "def A_star(Y):\n",
    "\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    if Y.ndim != 2 or Y.shape[0] != Y.shape[1]:\n",
    "        raise ValueError(\"Y must be a square matrix.\")\n",
    "    p = Y.shape[0]\n",
    "    Astar = np.zeros(int(p*(p-1)/2))\n",
    "\n",
    "    for i in range(1,p+1):\n",
    "\n",
    "        for j in range(1,p+1):\n",
    "           \n",
    "            if (i > j):\n",
    "                k = int( (i - j) + ((j - 1)/2)*(2*p - j) ) \n",
    "                Astar[k-1] = Y[i-1, j-1] + Y[ j-1, i-1]\n",
    "\n",
    "\n",
    "    return Astar\n",
    "\n",
    "def D_star(w: np.ndarray) -> np.ndarray:\n",
    "    w = np.asarray(w).ravel()\n",
    "    dStar = L_star(np.diag(w))\n",
    "    return  dStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69aad991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_cov\n",
      "[[1.         0.34982739 0.32699292 0.27549521 0.34886486]\n",
      " [0.34982739 1.         0.37785361 0.33174046 0.32484628]\n",
      " [0.32699292 0.37785361 1.         0.33200448 0.34886946]\n",
      " [0.27549521 0.33174046 0.33200448 1.         0.32947489]\n",
      " [0.34886486 0.32484628 0.34886946 0.32947489 1.        ]]\n",
      "S_prec\n",
      "[[ 1.27263721 -0.24947558 -0.19281752 -0.11937063 -0.25633942]\n",
      " [-0.24947558  1.32359962 -0.28620275 -0.21902718 -0.17092178]\n",
      " [-0.19281752 -0.28620275  1.32304704 -0.21528053 -0.23040203]\n",
      " [-0.11937063 -0.21902718 -0.21528053  1.25090233 -0.22424173]\n",
      " [-0.25633942 -0.17092178 -0.23040203 -0.22424173  1.29921337]]\n"
     ]
    }
   ],
   "source": [
    "log_rw_returns = pd.read_csv(\"log_rw_returns.csv\")\n",
    "\n",
    "S_cov = np.corrcoef(scale(log_rw_returns).T)\n",
    "print(\"S_cov\")\n",
    "print(S_cov)\n",
    "\n",
    "S_prec = np.linalg.pinv(S_cov)\n",
    "print(\"S_prec\")\n",
    "print(S_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6050ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w from L\n",
      "[0.24947558 0.19281752 0.11937063 0.25633942 0.28620275 0.21902718\n",
      " 0.17092178 0.21528053 0.23040203 0.22424173]\n",
      "w\n",
      "[0.24947558 0.19281752 0.11937063 0.25633942 0.28620275 0.21902718\n",
      " 0.17092178 0.21528053 0.23040203 0.22424173]\n",
      "Lw from w\n",
      "[[ 0.81800315 -0.24947558 -0.19281752 -0.11937063 -0.25633942]\n",
      " [-0.24947558  0.9256273  -0.28620275 -0.21902718 -0.17092178]\n",
      " [-0.19281752 -0.28620275  0.92470283 -0.21528053 -0.23040203]\n",
      " [-0.11937063 -0.21902718 -0.21528053  0.77792007 -0.22424173]\n",
      " [-0.25633942 -0.17092178 -0.23040203 -0.22424173  0.88190495]]\n",
      "Lstar from Lw\n",
      "[2.24258162 2.12834103 1.83466448 2.21258694 2.42273564 2.14160172\n",
      " 2.14937582 2.13318397 2.26741184 2.10830848]\n",
      "Aw from w\n",
      "[[0.         0.24947558 0.19281752 0.11937063 0.25633942]\n",
      " [0.24947558 0.         0.28620275 0.21902718 0.17092178]\n",
      " [0.19281752 0.28620275 0.         0.21528053 0.23040203]\n",
      " [0.11937063 0.21902718 0.21528053 0.         0.22424173]\n",
      " [0.25633942 0.17092178 0.23040203 0.22424173 0.        ]]\n",
      "w from A\n",
      "[0.24947558 0.19281752 0.11937063 0.25633942 0.28620275 0.21902718\n",
      " 0.17092178 0.21528053 0.23040203 0.22424173]\n",
      "Astar from Aw\n",
      "[0.49895117 0.38563504 0.23874126 0.51267883 0.57240551 0.43805436\n",
      " 0.34184357 0.43056106 0.46080405 0.44848345]\n",
      "Dstar from w\n",
      "[0.4422931  0.36884621 0.505815   0.53567834 0.46850276 0.42039737\n",
      " 0.46475611 0.47987761 0.47371731 0.31218815 0.44915694 0.47902028\n",
      " 0.4118447  0.36373931 0.40809805 0.42321955 0.41705925 0.37571005\n",
      " 0.40557339 0.33839781 0.29029242 0.33465116 0.34977266 0.34361236\n",
      " 0.54254217 0.47536659 0.4272612  0.47161995 0.48674144 0.48058114\n",
      " 0.50522993 0.45712454 0.50148329 0.51660478 0.51044448 0.38994896\n",
      " 0.43430771 0.4494292  0.4432689  0.38620232 0.40132381 0.39516351\n",
      " 0.44568256 0.43952226 0.45464375]\n"
     ]
    }
   ],
   "source": [
    "wL = w_from_L(S_prec)\n",
    "print(\"w from L\")\n",
    "print(wL)\n",
    "\n",
    "w = W_init(S_prec)\n",
    "print(\"w\")\n",
    "print(w)\n",
    "\n",
    "Lw = L_from_w(w)\n",
    "print(\"Lw from w\")\n",
    "print(Lw) \n",
    "\n",
    "Lstar = L_star(Lw)\n",
    "print(\"Lstar from Lw\")\n",
    "print(Lstar) \n",
    "\n",
    "Aw = A_from_w(w)\n",
    "print('Aw from w')\n",
    "print(Aw)\n",
    "\n",
    "wA = w_from_A(Aw)\n",
    "print('w from A')\n",
    "print(wA)\n",
    "\n",
    "Astar = A_star(Aw)\n",
    "print('Astar from Aw')\n",
    "print(Astar)\n",
    "\n",
    "Dstar = D_star(w)\n",
    "print('Dstar from w')\n",
    "print(Dstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb504f1",
   "metadata": {},
   "source": [
    "## Code From Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4242d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16414457 -0.3585202   0.31150615  0.07536903 -0.19249955]\n",
      " [-0.3585202   0.7830703  -0.68038345 -0.16461904  0.4204524 ]\n",
      " [ 0.31150615 -0.68038345  0.5911623   0.14303195 -0.36531695]\n",
      " [ 0.07536903 -0.16461904  0.14303195  0.03460664 -0.08838858]\n",
      " [-0.19249955  0.4204524  -0.36531695 -0.08838858  0.22575268]]\n"
     ]
    }
   ],
   "source": [
    "def L_update( wn, Phi_n, rho, p, k):\n",
    "\n",
    "    ''' \n",
    "    L_n: Laplace Matrix (Ln = Diag(Wn1) - Wn = Lwn) Laplacian operator “A Unified Framework for Structured Graph Learning via Spectral Constraints”\n",
    "    Phi_n: ADMM Dual Variable \n",
    "    rho: ADMM Hyperparameter\n",
    "    p: Number of time series\n",
    "    k: Clusters\n",
    "    '''\n",
    "    # Reference: Equation 16\n",
    "    \n",
    "    Y = L_from_w(wn) + Phi_n/rho\n",
    "\n",
    "    eigVals,eigVecs = np.linalg.eigh(Y)\n",
    "    U = eigVecs[:,p-k:]\n",
    "    R = np.diag(eigVals[p-k:])\n",
    "    I = np.eye(R.shape[0]) \n",
    "    Ln = 0.5 * U @ ( R + np.sqrt(  R**2 + 4/rho * I  ) ) @ U.T\n",
    "    return Ln\n",
    "\n",
    "p = Lw.shape[0]\n",
    "Phi_n = np.zeros((p,p)) # ADMM dual variable for Laplace Matrix\n",
    "rho = 1                 # ADMM hyperparameter.\n",
    "k = 1                   # Clusters\n",
    "\n",
    "\n",
    "Ln = L_update( w, Phi_n, rho, p, k)\n",
    "print(Ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93f872b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import multivariate_t\n",
    "\n",
    "# mean (mu)\n",
    "loc = [0., 0., 0., 0., 0.]\n",
    "\n",
    "# covariance (Sigma)\n",
    "shape = [\n",
    "    [1.5,     0.75,    0.375,   0.1875,  0.09375],\n",
    "    [0.75,    1.5,     0.75,    0.375,   0.1875 ],\n",
    "    [0.375,   0.75,    1.5,     0.75,    0.375  ],\n",
    "    [0.1875,  0.375,   0.75,    1.5,     0.75   ],\n",
    "    [0.09375, 0.1875,  0.375,   0.75,    1.5    ],\n",
    "]\n",
    "\n",
    "# degrees of freedom\n",
    "df = 6.0\n",
    "\n",
    "# Create a frozen multivariate_t object\n",
    "# This allows fixing the parameters and then calling methods like rvs()\n",
    "dist = multivariate_t(loc=loc, shape=shape, df=df)\n",
    "\n",
    "# Generate samples\n",
    "num_samples = 1000\n",
    "samples = dist.rvs(size=num_samples)\n",
    "samples.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea9bf5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: [-0.01214302 -0.04084377 -0.02271728  0.01501869  0.03775479]\n",
      "nu: 6.376636097962273\n",
      "Sigma:\n",
      " [[1.50124719 0.71356759 0.3875365  0.18888086 0.10600994]\n",
      " [0.71356759 1.49597974 0.72514147 0.38102188 0.15437081]\n",
      " [0.3875365  0.72514147 1.56357744 0.6987182  0.34110254]\n",
      " [0.18888086 0.38102188 0.6987182  1.49837025 0.7529836 ]\n",
      " [0.10600994 0.15437081 0.34110254 0.7529836  1.55807296]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import slogdet\n",
    "from scipy.special import digamma, polygamma, gammaln\n",
    "# Reference\n",
    "# https://zouyuxin.github.io/Note/EMtDistribution.pdf\n",
    "# https://shoichimidorikawa.github.io/Lec/ProbDistr/t-e.pdf\n",
    "def fit_multivariate_t(\n",
    "    X,\n",
    "    nu_init=10.0,\n",
    "    max_iter=200,\n",
    "    tol=1e-6,\n",
    "    fix_nu=None,\n",
    "    jitter=1e-6,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate (mu, Sigma, nu) for a multivariate Student's t via EM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        Data.\n",
    "    nu_init : float\n",
    "        Initial degrees of freedom (ignored if fix_nu is not None).\n",
    "    max_iter : int\n",
    "        Maximum EM iterations.\n",
    "    tol : float\n",
    "        Relative tolerance on log-likelihood for convergence.\n",
    "    fix_nu : float or None\n",
    "        If set, keep nu fixed at this value.\n",
    "    jitter : float\n",
    "        Diagonal jitter multiplier for numerical stability.\n",
    "    verbose : bool\n",
    "        Print progress if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu : array, shape (p,)\n",
    "    Sigma : array, shape (p, p)\n",
    "    nu : float\n",
    "    history : dict with 'loglik'\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Initialize\n",
    "    mu = X.mean(axis=0)\n",
    "    # sample covariance (unbiased=False), add tiny jitter\n",
    "    centered0 = X - mu\n",
    "    Sigma = centered0.T @ centered0 / n\n",
    "    Sigma += np.eye(p) * (jitter * np.trace(Sigma) / p + 1e-12)\n",
    "    nu = float(nu_init if fix_nu is None else fix_nu)\n",
    "\n",
    "    def mahal_sq(Sigma, X, mu):\n",
    "        # δ_i = (x_i - mu)^T Sigma^{-1} (x_i - mu)\n",
    "        L = np.linalg.cholesky(Sigma)\n",
    "        Y = np.linalg.solve(L, (X - mu).T)   # shape (p, n)\n",
    "        return np.sum(Y * Y, axis=0)         # shape (n,)\n",
    "\n",
    "    def loglik(mu, Sigma, nu):\n",
    "        # log-likelihood of multivariate t\n",
    "        sgn, logdet = slogdet(Sigma)\n",
    "        if sgn <= 0:\n",
    "            return -np.inf\n",
    "        delta = mahal_sq(Sigma, X, mu)\n",
    "        term1 = gammaln((nu + p) / 2) - gammaln(nu / 2)\n",
    "        term2 = - (p / 2) * np.log(nu * np.pi) - 0.5 * logdet\n",
    "        term3 = - ((nu + p) / 2) * np.log1p(delta / nu)\n",
    "        return np.sum(term1 + term2 + term3)\n",
    "\n",
    "    ll_old = -np.inf\n",
    "    history = {'loglik': []}\n",
    "\n",
    "    for it in range(1, max_iter + 1):\n",
    "        # E-step\n",
    "        delta = mahal_sq(Sigma, X, mu)\n",
    "        w = (nu + p) / (nu + delta)  # E[lambda_i | x_i]\n",
    "        eloglam = digamma((nu + p) / 2) - np.log((nu + delta) / 2)  # E[log lambda_i | x_i]\n",
    "\n",
    "        # M-step: mu (weighted mean)\n",
    "        sumw = w.sum()\n",
    "        mu = (w[:, None] * X).sum(axis=0) / sumw\n",
    "\n",
    "        # M-step: Sigma\n",
    "        Xc = X - mu\n",
    "        Sigma = (Xc.T * w) @ Xc / n\n",
    "        # stabilize\n",
    "        Sigma += np.eye(p) * (jitter * np.trace(Sigma) / p + 1e-12)\n",
    "\n",
    "        # M-step: nu (solve for root of dQ/dnu = 0) unless fixed\n",
    "        if fix_nu is None:\n",
    "            # f(nu) = log(nu/2) - psi(nu/2) + 1 + (1/n) * sum(E[log lambda_i] - E[lambda_i]) = 0\n",
    "            c = (eloglam.mean() - w.mean())\n",
    "\n",
    "            def f(nu_):\n",
    "                return np.log(nu_ / 2.0) - digamma(nu_ / 2.0) + 1.0 + c\n",
    "\n",
    "            def fprime(nu_):\n",
    "                return 1.0 / nu_ - 0.5 * polygamma(1, nu_ / 2.0)\n",
    "\n",
    "            # Newton update with simple guarding\n",
    "            nu_new = max(nu, 2.01)  # keep > 2 so covariance exists\n",
    "            for _ in range(30):\n",
    "                val = f(nu_new)\n",
    "                der = fprime(nu_new)\n",
    "                step = val / der\n",
    "                nu_new = nu_new - step\n",
    "                if nu_new < 2.01:\n",
    "                    nu_new = 2.01\n",
    "                if abs(step) / nu_new < 1e-6:\n",
    "                    break\n",
    "            nu = float(nu_new)\n",
    "        else:\n",
    "            nu = float(fix_nu)\n",
    "\n",
    "        # Evaluate log-likelihood and check convergence\n",
    "        ll = loglik(mu, Sigma, nu)\n",
    "        history['loglik'].append(ll)\n",
    "        if verbose:\n",
    "            print(f\"iter {it:3d}: ll={ll:.6f}, nu={nu:.4f}\")\n",
    "\n",
    "        if np.isfinite(ll_old):\n",
    "            if abs(ll - ll_old) / (abs(ll_old) + 1e-12) < tol:\n",
    "                break\n",
    "        ll_old = ll\n",
    "\n",
    "    return mu, Sigma, nu, history\n",
    "\n",
    "\n",
    "# X: (n_samples, n_features) data\n",
    "\n",
    "mu, Sigma, nu, history = fit_multivariate_t(\n",
    "samples,\n",
    "nu_init=30.0,\n",
    "max_iter=200,\n",
    "tol=1e-8,\n",
    "fix_nu=None,\n",
    "jitter=1e-6,\n",
    "verbose=False,\n",
    ")\n",
    "print(\"mu:\", mu)\n",
    "print(\"nu:\", nu)\n",
    "print(\"Sigma:\\n\", Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610c8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_update( x, beta, rho, a, w_n_prev, w_n, L_n, Vn, p, k, d, Tn, nu, eta, Phi_n, mu_n, z_n):\n",
    "\n",
    "    ''' \n",
    "    x: observation for each time series\n",
    "    p: Number of Time Series\n",
    "    a: VAR coefficients\n",
    "    k: Number of Clusters\n",
    "    nu: Student T degrees of freedom\n",
    "    Vn: Laplacian spectral constraint\n",
    "    Tn: Number of observations in a Frame \n",
    "    eta: regularization term\n",
    "    d: Node degree constraint\n",
    "\n",
    "    Phi_n: ADMM dual variable\n",
    "    mu_n: ADMM dual variable\n",
    "    z_n: ADMM dual variable\n",
    "    '''\n",
    "\n",
    "    assert Vn.shape[0] == p and Vn.shape[1] == k\n",
    "\n",
    "    Lstar = L_star(w) \n",
    "    dstar = D_star(w)\n",
    "\n",
    "    u_n = w_n - a * w_n_prev # Vector Autoregressive variable\n",
    "\n",
    "    cth = np.sqrt( (2*beta)/(rho*(4*rho -1)) ) * np.ones(len(w_n))\n",
    "\n",
    "    S_sum = 0\n",
    "    for i in range(0,Tn):\n",
    "        S_sum += ( x[i,:]*x[i,:].T )/( x[i,:].T @ L_n @ x[i,:] + nu )\n",
    "\n",
    "    S = ( (p + nu)/Tn ) * S_sum\n",
    "\n",
    "    aw = L_star @ ( S + Phi_n + rho*(L_star - L_n) + eta * Vn@Vn.T )\n",
    "\n",
    "    bw = -mu_n - rho*( u_n + a*w_n_prev ) + d_star @ ( z_n - rho * ( d - d_star*w_n ) )\n",
    "\n",
    "    cw = (1 - (rho)/(rho*(4*p-1))) * wn - (1)/( rho*(4*p -1) ) * (aw + bw)\n",
    "\n",
    "    wn = (cw > cth) * cw\n",
    "\n",
    "    return wn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convexfi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
